#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Filename : extract_means_exp2.py
# @Version : 2.1
# @Date : 2019-10-13-15-23
# @Project: jesstrain
# @AUTHOR
# : jessir
'''
Removes some hardcoding of differences across experiments
'''

import numpy as np
import pandas as pd
import os
import sys
import glob
from analysis_tools import bearingError, positionError

# User parameters
#teams = range(19,28+1) # Teams list
#sessions = range(1,2+1) # Sessions per teamh
code_directory = ('C:\\Users\\jesir\\PycharmProjects\jesstrain')
os.chdir(code_directory)

# Set the directory
# Get code path - currently inside jesstrain NOT WORKING
##code_directory = os.path.dirname(sys.argv[0])  #Note this won't work when typed into console
##os.chdir(code_directory)
# Change directory to data folder
os.chdir('..')
os.chdir('data')
data_directory = os.getcwd()

# Get list of team folders and team numbers
team_folder_list = glob.glob('Team*')

df_condlist = pd.read_csv('condlist.csv')
df_sst = pd.read_csv('Sonar_start_time.csv')  # Get sonar start times

# Set up variables used for all analysis
sessions = [1,2]
endtime = 3700  # total number of seconds to look at
tpdur = 20 # number of seconds per time point
tpnum = int(endtime/tpdur)
ypm = 33.756 # Yards per minute travelling at 1 knot = 33.756
pointsrange = .33 # Solution must be within this proportion of range in order # to score a point
zigdegrees = 30 # How many degrees change in course to qualify for a zig
sonarrange = 30000 # Max range for detection (as told to participants)
bearerrmax = 20 # bearing errors outside of this considered outliers
minRT = 10 # minimum allowable time since last solution 

amcols = ['Team','Session','Integration']   
allmeansdf = pd.DataFrame(np.nan,index = [], columns = amcols)
epochdf = pd.DataFrame(np.nan,index = [], columns = amcols)
allmeansintdf = pd.DataFrame(np.nan,index = [], columns = amcols)
epochintdf = pd.DataFrame(np.nan,index = [], columns = amcols)

am = 0
firstcompleted= 0
                    
for team_folder in team_folder_list:

    team = int(team_folder.strip('Team '))
    os.chdir(data_directory + '\\' + team_folder)
    session_folder_list = glob.glob('cruse-*')

    for session in sessions:

        session_folder = session_folder_list[session-1]  # minus 1 to match indexing
        print(team_folder)
        print('Session ' + str(session))
        print(session_folder)
        os.chdir(data_directory + '\\' + team_folder + '\\' + session_folder)

        condlist_criteria = (df_condlist['Team'] == team)
        integration_condition = df_condlist[condlist_criteria][('Session' + str(session) + '_Intcond')].iloc[0]
        scenario_num = str(df_condlist[condlist_criteria][('Session' + str(session) + '_Scenario')].iloc[0])
        condition_label = integration_condition + '_' + scenario_num

        # Import necessary files into dataframes
        df_sl_all = pd.read_csv('sl_all_%s.csv' % condition_label)  # SL generated by
        df_sl = pd.read_csv('sl_%s.csv' % condition_label)  # All solutions entered. Includes initial solution set by sonar
        df_son = pd.read_csv('son_%s.csv' % condition_label)  # All solutions entered. Includes initial solution set by sonar
        #df_tssltp = pd.read_csv('tssltp_OI3_%s.csv' % condition_label)
        df_ann = pd.read_csv('annotations.csv')  # TPC and Sonar annotations
        df_atw = pd.read_csv('atwit.csv')  # atwit scores
        df_atw = df_atw[df_atw.aw_console != 'COMMAND']  # remove rows from console "command"
        df_atw['aw_workload'] = df_atw['aw_workload'].replace(999, np.NaN)  # replace 999 with NA
        df_ts = pd.read_csv('target_solution.csv')  # Ground truth for every vessel every 20s

        # Get console/operator names used in this experiment from data
        consoles = pd.unique(df_atw['aw_console'])
        consoles.sort()

        # ts_all_cons =
        ts_all_cons = pd.unique(df_ts['ts_id']) 
        ts_all_n = ts_all_cons.size   #total number of contacts listed in TS, including those not yet detected
        sl_all_cons = pd.unique(df_sl_all['sl_sid']) # Total number of sierra numbers assigned
        sl_ts_all_cons = pd.unique(df_sl_all['sl_ts_id']) # All TS contacts detected
        sl_ts_cons = pd.unique(df_sl['sl_ts_id']) # All TS contacts with a TMA solution

# Combine all means
        
        allmeansdf.loc[am,'Team'] = team
        allmeansdf.loc[am,'Session'] = session
        allmeansdf.loc[am,'Integration'] = integration_condition
        #allmeansdf.loc[am,'DRT condition'] = DRTcond
        allmeansdf.loc[am,'Scenario'] = scenario_num
        allmeansdf.loc[am,'Percent contacts detected'] = sl_ts_all_cons.size/ts_all_n*100
        allmeansdf.loc[am,'Percent contacts with TMA solutions'] = sl_ts_cons.size/ts_all_n*100
        allmeansdf.loc[am,'Number solutions'] = df_sl.shape[0]
        allmeansdf.loc[am,'Position Error averaged across solutions'] = df_sl['sl_PE'].mean()
        allmeansdf.loc[am,'Position Error/Range averaged across solutions'] = df_sl['sl_PE_over_range'].mean()
        allmeansdf.loc[am,'Bearing Error across solutions'] = df_sl['sl_bearingError'].mean()        
        #allmeansdf.loc[am,'Position Error over time averaged'] = df_tssltp['tp_meanPE'].mean()
        #allmeansdf.loc[am,'Position Error/Range over time averaged'] = df_tssltp['tp_meanPEoverRange'].mean()
        #allmeansdf.loc[am,'Bearing Error over time averaged'] = df_tssltp['tp_meanBearingError'].mean()
        #allmeansdf.loc[am,'TPE'] = df_tssltp['tp_prodweightedPE'].mean()
        allmeansdf.loc[am,'Low Priority Class PE'] = df_sl.loc[(df_sl.loc[:,'sl_class_weight']==1),'sl_PE'].mean()
        allmeansdf.loc[am,'Medium Priority Class PE'] =  df_sl.loc[(df_sl.loc[:,'sl_class_weight']==2),'sl_PE'].mean()
        allmeansdf.loc[am,'High Priority Class PE'] =  df_sl.loc[(df_sl.loc[:,'sl_class_weight']==3),'sl_PE'].mean()        
        allmeansdf.loc[am,'First TMA Solution RT'] = df_sl.loc[(df_sl.loc[:,'sl_contact_SLcount']==1),'sl_RT'].mean()
        allmeansdf.loc[am,'Solution Update RT'] = df_sl['sl_updateRT'].mean()  
        allmeansdf.loc[am,'TMA RT'] = df_sl['sl_tmaRT'].mean() 
        allmeansdf.loc[am,'TPC annocations count'] = (df_ann[df_ann['an_source'].str.contains("TPC")]).shape[0]
        allmeansdf.loc[am,'ATWIT all'] = df_atw['aw_workload'].mean()
        allmeansdf.loc[am,'Sonar_TID_RT'] = df_son['son_TID_RT'].mean()
        allmeansdf.loc[am,'Sonar_SCID_RT'] = df_son['son_SCID_RT'].mean()
        #allmeansdf.loc[am,'Percent_Weighted_points'] = df_tssltp['tp_prodweightedPE_points'].mean() * 100
        #allmeansdf.loc[am,'Points_count'] = df_tssltp['tp_meanrangepoints'].mean()*100
        TMA_count = sum('TMA' in console for console in consoles)  # Count how many TMAs
        for tma in range(1, TMA_count + 1):
            tmaname = 'TMA' + str(tma)
            allmeansdf.loc[am, tmaname + ' Position Error averaged across solutions'] = df_sl.loc[(df_sl.loc[:, 'sl_console'] == tmaname), 'sl_PE'].mean()
            allmeansdf.loc[am, tmaname + ' Position Error/Range averaged across solutions'] =df_sl.loc[(df_sl.loc[:, 'sl_console'] == tmaname), 'sl_PE_over_range'].mean()
            allmeansdf.loc[am, tmaname +  ' RT'] = df_sl.loc[(df_sl.loc[:, 'sl_console'] == tmaname), 'sl_tmaRT'].mean()

        
        # Get all epoch data
        # epoch1crit = (df_tssltp['tp_time'] >= 0) & (df_tssltp['tp_time'] <= np.floor(endtime/3))
        # epoch2crit = (df_tssltp['tp_time'] > np.floor(endtime/3)) & (df_tssltp['tp_time'] <= np.floor(endtime/3*2))
        # epoch3crit = (df_tssltp['tp_time'] > np.floor(endtime/3*2)) & (df_tssltp['tp_time'] <= endtime)
        # half1crit = (df_tssltp['tp_time'] >= 0) & (df_tssltp['tp_time'] <= np.floor(endtime/2))
        # half2crit = (df_tssltp['tp_time'] > np.floor(endtime/2)) & (df_tssltp['tp_time'] <= endtime)
        # epochdf.loc[am,'Team'] = team
        # epochdf.loc[am,'Session'] = session
        # epochdf.loc[am,'Integration'] = integration_condition
        # #epochdf.loc[am,'DRT condition'] = DRTcond
        # epochdf.loc[am,'Scenario'] = scenario_num
        # epochdf.loc[am,'Epoch1 Position Error over time'] = df_tssltp[epoch1crit]['tp_meanPE'].mean()
        # epochdf.loc[am,'Epoch2 Position Error over time'] = df_tssltp[epoch2crit]['tp_meanPE'].mean()
        # epochdf.loc[am,'Epoch3 Position Error over time'] = df_tssltp[epoch3crit]['tp_meanPE'].mean()
        # epochdf.loc[am,'Epoch1 Position Error/Range over time'] = df_tssltp[epoch1crit]['tp_meanPEoverRange'].mean()
        # epochdf.loc[am,'Epoch2 Position Error/Range over time'] = df_tssltp[epoch2crit]['tp_meanPEoverRange'].mean()
        # epochdf.loc[am,'Epoch3 Position Error/Range over time'] = df_tssltp[epoch3crit]['tp_meanPEoverRange'].mean()
        # epochdf.loc[am,'Epoch1 PercentWeighted Position Error over time'] = df_tssltp[epoch1crit]['tp_prodweightedPE'].mean() # product weighted PE
        # epochdf.loc[am,'Epoch2 PercentWeighted Position Error over time'] = df_tssltp[epoch2crit]['tp_prodweightedPE'].mean()
        # epochdf.loc[am,'Epoch3 PercentWeighted Position Error over time'] = df_tssltp[epoch3crit]['tp_prodweightedPE'].mean()
        # epochdf.loc[am,'Epoch1 PercentWeighted Points'] = df_tssltp[epoch1crit]['tp_prodweightedPE_points'].mean()*100 # product weighted PE
        # epochdf.loc[am,'Epoch2 PercentWeighted Points'] = df_tssltp[epoch2crit]['tp_prodweightedPE_points'].mean()*100
        # epochdf.loc[am,'Epoch3 PercentWeighted Points'] = df_tssltp[epoch3crit]['tp_prodweightedPE_points'].mean()*100
        # epochdf.loc[am,'Half1 Position Error over time'] = df_tssltp[half1crit]['tp_meanPE'].mean()
        # epochdf.loc[am,'Half2 Position Error over time'] = df_tssltp[half2crit]['tp_meanPE'].mean()
        # epochdf.loc[am,'Half1 Position Error/Range over time'] = df_tssltp[half1crit]['tp_meanPEoverRange'].mean()
        # epochdf.loc[am,'Half2 Position Error/Range over time'] = df_tssltp[half2crit]['tp_meanPEoverRange'].mean()
        # epochdf.loc[am,'Half1 PercentWeighted Position Error over time'] = df_tssltp[half1crit]['tp_prodweightedPE'].mean()
        # epochdf.loc[am,'Half2 PercentWeighted Position Error over time'] = df_tssltp[half2crit]['tp_prodweightedPE'].mean()
        
        am += 1
   
    # at end of a team
    amteamcrit = (allmeansdf['Team'] == team)
    epteamcrit = (epochdf['Team'] == team)
    if firstcompleted == 0:
        allmeansintdf = pd.DataFrame(np.nan,index = [], columns = list(allmeansdf))
        epochintdf = pd.DataFrame(np.nan,index = [], columns = list(epochdf))
        firstcompleted = 1;
    
    allmeansintdf = allmeansintdf.append(allmeansdf[amteamcrit].mean(),ignore_index = True, sort = False)
    allmeansintdf.loc[:,'Integration'].iloc[-1] = integration_condition
    epochintdf = epochintdf.append(epochdf[epteamcrit].mean(),ignore_index = True, sort = False) ### this sorts cols, very annoying!
    epochintdf.loc[:,'Integration'].iloc[-1] = integration_condition

# # Add rows of averages at the bottom
# allmeansdf = allmeansdf.append(allmeansdf.loc[(allmeansdf.loc[:,'Integration']=='High') & (allmeansdf.loc[:,'DRT condition']=='N'),:].mean(),ignore_index = True, sort = False)
# allmeansdf.loc[:,'Integration'].iloc[-1] = 'High'
# allmeansdf.loc[:,'DRT condition'].iloc[-1] = 'N'
# #allmeansdf.loc[:,'Team'].iloc[-1] = 'TOTAL'
# allmeansdf = allmeansdf.append(allmeansdf.loc[(allmeansdf.loc[:,'Integration']=='High') & (allmeansdf.loc[:,'DRT condition']=='D'),:].mean(),ignore_index = True, sort = False)
# allmeansdf.loc[:,'Integration'].iloc[-1] = 'High'
# allmeansdf.loc[:,'DRT condition'].iloc[-1] = 'D'
# #allmeansdf.loc[:,'Team'].iloc[-1] = 'TOTAL'
# allmeansdf = allmeansdf.append(allmeansdf.loc[(allmeansdf.loc[:,'Integration']=='Low') & (allmeansdf.loc[:,'DRT condition']=='N'),:].mean(),ignore_index = True, sort = False)
# allmeansdf.loc[:,'Integration'].iloc[-1] = 'Low'
# allmeansdf.loc[:,'DRT condition'].iloc[-1] = 'N'
# #allmeansdf.loc[:,'Team'].iloc[-1] = 'TOTAL'
# allmeansdf = allmeansdf.append(allmeansdf.loc[(allmeansdf.loc[:,'Integration']=='Low') & (allmeansdf.loc[:,'DRT condition']=='D'),:].mean(),ignore_index = True, sort = False)
# allmeansdf.loc[:,'Integration'].iloc[-1] = 'Low'
# allmeansdf.loc[:,'DRT condition'].iloc[-1] = 'D'
# allmeansdf = allmeansdf.append(allmeansdf.loc[(allmeansdf.loc[:,'DRT condition']=='N'),:].mean(),ignore_index = True, sort = False)
# allmeansdf.loc[:,'DRT condition'].iloc[-1] = 'N'
# #allmeansdf.loc[:,'Team'].iloc[-1] = 'TOTAL'
# allmeansdf = allmeansdf.append(allmeansdf.loc[(allmeansdf.loc[:,'DRT condition']=='D'),:].mean(),ignore_index = True, sort = False)
# allmeansdf.loc[:,'DRT condition'].iloc[-1] = 'D'
# allmeansdf.loc[:,'Team'].iloc[-6:-1] = 'TOTAL'
# allmeansdf.loc[:,'Team'].iloc[-1] = 'TOTAL'
#
# # Add a row of averages at the bottom
# allmeansintdf = allmeansintdf.append(allmeansintdf.loc[(allmeansintdf.loc[:,'Integration']=='High'),:].mean(),ignore_index = True, sort = False)
# allmeansintdf.loc[:,'Integration'].iloc[-1] = 'High'
# allmeansintdf.loc[:,'Team'].iloc[-1] = 'TOTAL'
# allmeansintdf = allmeansintdf.append(allmeansintdf.loc[(allmeansintdf.loc[:,'Integration']=='Low'),:].mean(),ignore_index = True, sort = False)
# allmeansintdf.loc[:,'Integration'].iloc[-1] = 'Low'
# allmeansintdf.loc[:,'Team'].iloc[-1] = 'TOTAL'
#
os.chdir(data_directory)
allmeansdf.to_csv('OI3 Means_all_teams.csv')     
epochdf.to_csv('OI3 Epoch means_all_teams.csv') 
allmeansintdf.to_csv('OI3 Means all teams Integ.csv')     
epochintdf.to_csv('OI3 Epoch means all teams Integ.csv') 
