# -*- coding: utf-8 -*-
"""
Created on Fri Apr 13 2019

Cleans individual scenario data
- Converts units across all files
- Calculates position error for each solution
- Calculates position error for each contact over time and combines across all contacts

@author: ironsj
"""
import numpy as np
import pandas as pd
import os

# User parameters
teams = range(17,17+1) # Teams list
sessions = range(1,2+1) # Sessions per team
endtime = 3700  # total number of seconds to look at

condcols = ['Team','Session','Integration', 'Configuration']  
maindir = ('\\\\homes-stl\\home1\\ironsj\\Documents\\CRUSE\\Experiment 1 Integration & Config study\\Data')
#maindir = ('\\\\homes-stl\\home1\\ironsj\\Documents\\CRUSE\\Experiment 1 Integration & Config study\\Data')
os.chdir(maindir)
df_condlist = pd.read_csv('condlist.csv')
df_sst = pd.read_csv('Sonar_start_time.csv') # Get sonar start times
# Save any flagged issues in this file in the main directory
flagfile = open('flagfile.txt','w')
  
# Set up variables used for all analysis
tpdur = 20 # number of seconds per time point
tpnum = int(endtime/tpdur)
ypm = 33.756 # Yards per minute travelling at 1 knot = 33.756
pointsrange = .33 # Solution must be within this proportion of range in order # to score a point
zigdegrees = 30 # How many degrees change in course to qualify for a zig
sonarrange = 30000 # Max range for detection (as told to participants)
bearerrmax = 20 # bearing errors outside of this considered outliers
minRT = 10 # minimum allowable time since last solution 
# Weights from highest 3 to lowest 1
classweightdict = {'Warship':3,'Fishing':2,'Merchant':1, 'Merchant B':1,'Merchant C':1} 
rangeweightdict = {5000:3,10000:2,15000:1}
courseweightdict = {'Closing':3,'Opening':1}
zigweightdict = {'Zigging':3,'Notzigging':1}

amcols = ['Team','Session','Configuration','Integration']   
allmeansdf = pd.DataFrame(np.nan,index = [0], columns = amcols)
epochdf = pd.DataFrame(np.nan,index = [0], columns = amcols)
allmeansintdf = pd.DataFrame(np.nan,index = [0], columns = amcols)
epochintdf = pd.DataFrame(np.nan,index = [0], columns = amcols)

am = 0
                    
for team in teams:
    for session in sessions:
        
        print('Team ' + str(team))
        print('Session ' + str(session))
        flagfile.write('Team ' + str(team) + 'Session ' + str(session) + '\n')
        
        clcrit = (df_condlist['Team']==team) & (df_condlist['Session']==session)
        datafolder = df_condlist[clcrit]['Directory'].iloc[0]
        intcond = df_condlist[clcrit]['Integration'].iloc[0]
        configcond = df_condlist[clcrit]['Configuration'].iloc[0]
        scennum = str(df_condlist[clcrit]['Scenario'].iloc[0])
        condlabel = intcond + '_' + configcond + '_' + scennum
        datadir = (maindir + r'\Team ' + str(team) + '\\' + datafolder)
        os.chdir(datadir)
        
        # Import necessary files into dataframes
        df_sl_all = pd.read_csv('sl_all_%s.csv' % condlabel) # SL generated by 
        df_sl = pd.read_csv('sl_%s.csv' % condlabel) # All solutions entered. Includes initial solution set by sonar
        df_son = pd.read_csv('son_%s.csv' % condlabel) # All solutions entered. Includes initial solution set by sonar
        df_tssltp = pd.read_csv('tssltp_OI3_%s.csv' % condlabel)
        df_ann = pd.read_csv('annotations.csv') # TPC and Sonar annotations
        df_atw = pd.read_csv('atwit.csv') # atwit scores
        df_atw[df_atw.aw_console != 'COMMAND'] # remove rows from console "command" 
        df_atw['aw_workload'] = df_atw['aw_workload'].replace(999,np.NaN) # replace 999 with NA
        
        ts_all_cons = pd.unique(df_sl['sl_ts_id']) 
        ts_all_n = ts_all_cons.size   #total number of contacts listed in TS, including those not yet detected
        detect_cons = pd.unique(df_sl_all['sl_sid']) 
        solution_cons = pd.unique(df_sl_all['sl_sid']) 

# Combine all means
        
        allmeansdf.loc[am,'Team'] = team
        allmeansdf.loc[am,'Session'] = session
        allmeansdf.loc[am,'Configuration'] = configcond
        allmeansdf.loc[am,'Integration'] = intcond
        allmeansdf.loc[am,'Percent contacts detected'] = detect_cons.size/ts_all_n*100
        allmeansdf.loc[am,'Percent contacts with TMA solutions'] = solution_cons.size/ts_all_n*100
        allmeansdf.loc[am,'Number solutions'] = df_sl.shape[0]
        allmeansdf.loc[am,'Position Error averaged across solutions'] = df_sl['sl_PE'].mean()
        allmeansdf.loc[am,'Position Error/Range averaged across solutions'] = df_sl['sl_PE_over_range'].mean()
        allmeansdf.loc[am,'Bearing Error across solutions'] = df_sl['sl_bearingError'].mean()        
        allmeansdf.loc[am,'Position Error over time averaged'] = df_tssltp['tp_meanPE'].mean()
        allmeansdf.loc[am,'Position Error/Range over time averaged'] = df_tssltp['tp_meanPEoverRange'].mean()    
        allmeansdf.loc[am,'Priority weighted Position Error over time averaged'] = df_tssltp['tp_prodweightedPE'].mean() 
        allmeansdf.loc[am,'Low Priority Class PE'] = df_sl.loc[(df_sl.loc[:,'sl_class_weight']==1),'sl_PE'].mean()
        allmeansdf.loc[am,'Medium Priority Class PE'] =  df_sl.loc[(df_sl.loc[:,'sl_class_weight']==2),'sl_PE'].mean()
        allmeansdf.loc[am,'High Priority Class PE'] =  df_sl.loc[(df_sl.loc[:,'sl_class_weight']==3),'sl_PE'].mean()        
        allmeansdf.loc[am,'First TMA Solution RT'] = df_sl.loc[(df_sl.loc[:,'sl_contact_SLcount']==1),'sl_RT'].mean()
        allmeansdf.loc[am,'Solution Update RT'] = df_sl['sl_updateRT'].mean()  
        allmeansdf.loc[am,'TMA RT'] = df_sl['sl_tmaRT'].mean() 
        allmeansdf.loc[am,'TPC annocations count'] = (df_ann[df_ann['an_source'].str.contains("TPC")]).shape[0]
        allmeansdf.loc[am,'ATWIT all'] = df_atw['aw_workload'].mean()
        allmeansdf.loc[am,'Sonar_TID_RT'] = df_son['son_TID_RT'].mean()
        allmeansdf.loc[am,'Sonar_SCID_RT'] = df_son['son_SCID_RT'].mean()
        allmeansdf.loc[am,'Percent_Weighted_points'] = df_tssltp['tp_prodweightedPE_points'].mean() * 100
        allmeansdf.loc[am,'Points_count'] = df_tssltp['tp_meanrangepoints'].mean()*100
        
        # Get all epoch data
        epoch1crit = (df_tssltp['tp_time'] >= 0) & (df_tssltp['tp_time'] <= np.floor(endtime/3)) 
        epoch2crit = (df_tssltp['tp_time'] > np.floor(endtime/3)) & (df_tssltp['tp_time'] <= np.floor(endtime/3*2)) 
        epoch3crit = (df_tssltp['tp_time'] > np.floor(endtime/3*2)) & (df_tssltp['tp_time'] <= endtime) 
        half1crit = (df_tssltp['tp_time'] >= 0) & (df_tssltp['tp_time'] <= np.floor(endtime/2)) 
        half2crit = (df_tssltp['tp_time'] > np.floor(endtime/2)) & (df_tssltp['tp_time'] <= endtime) 
        epochdf.loc[am,'Team'] = team
        epochdf.loc[am,'Session'] = session
        epochdf.loc[am,'Configuration'] = configcond
        epochdf.loc[am,'Integration'] = intcond
        epochdf.loc[am,'Epoch1 Position Error over time'] = df_tssltp[epoch1crit]['tp_meanPE'].mean()
        epochdf.loc[am,'Epoch2 Position Error over time'] = df_tssltp[epoch2crit]['tp_meanPE'].mean()
        epochdf.loc[am,'Epoch3 Position Error over time'] = df_tssltp[epoch3crit]['tp_meanPE'].mean()
        epochdf.loc[am,'Epoch1 Position Error/Range over time'] = df_tssltp[epoch1crit]['tp_meanPEoverRange'].mean()
        epochdf.loc[am,'Epoch2 Position Error/Range over time'] = df_tssltp[epoch2crit]['tp_meanPEoverRange'].mean()
        epochdf.loc[am,'Epoch3 Position Error/Range over time'] = df_tssltp[epoch3crit]['tp_meanPEoverRange'].mean()  
        epochdf.loc[am,'Epoch1 PercentWeighted Position Error over time'] = df_tssltp[epoch1crit]['tp_prodweightedPE'].mean() # product weighted PE
        epochdf.loc[am,'Epoch2 PercentWeighted Position Error over time'] = df_tssltp[epoch2crit]['tp_prodweightedPE'].mean()
        epochdf.loc[am,'Epoch3 PercentWeighted Position Error over time'] = df_tssltp[epoch3crit]['tp_prodweightedPE'].mean() 
        epochdf.loc[am,'Half1 Position Error over time'] = df_tssltp[half1crit]['tp_meanPE'].mean()
        epochdf.loc[am,'Half2 Position Error over time'] = df_tssltp[half2crit]['tp_meanPE'].mean()
        epochdf.loc[am,'Half1 Position Error/Range over time'] = df_tssltp[half1crit]['tp_meanPEoverRange'].mean()
        epochdf.loc[am,'Half2 Position Error/Range over time'] = df_tssltp[half2crit]['tp_meanPEoverRange'].mean()
        epochdf.loc[am,'Half1 PercentWeighted Position Error over time'] = df_tssltp[half1crit]['tp_prodweightedPE'].mean()
        epochdf.loc[am,'Half2 PercentWeighted Position Error over time'] = df_tssltp[half2crit]['tp_prodweightedPE'].mean()
        
        am += 1
   
    # at end of a team
#    amteamcrit = (allmeansdf['Team'] == team)
#    allmeansintdf = allmeansintdf.append(allmeansdf[amteamcrit].mean(),ignore_index = True)
#    allmeansintdf.loc[team,'Integration'] = intcond
#    allmeansintdf.drop(allmeansintdf.index[0])
#    epteamcrit = (epochdf['Team'] == team)
#    epochintdf = epochintdf.append(epochdf[epteamcrit].mean(),ignore_index = True) ### this sorts cols, very annoying!
#    epochintdf.loc[team,'Integration'] = intcond
#    epochintdf.drop(epochintdf.index[0])

    
    
os.chdir(maindir) 
allmeansdf.to_csv('OI3 Means Experts.csv')     
epochdf.to_csv('OI3 Epoch means Experts.csv') 
#allmeansintdf.to_csv('OI1 Means Experts Integ.csv')     
#epochintdf.to_csv('OI1 Epoch means Integ.csv') 
